{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('tf': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "42641d1e4ddc0439bc830f06160e1b86a530aa5e4e7d97ad1497406e82138f19"
      }
    },
    "interpreter": {
      "hash": "00355bbddba1116272bba4883f6d673f226b023cbceb401470502a5ceca7c612"
    },
    "colab": {
      "name": "02_intro_analysis_with_solutions.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oll7znq_DJ1G"
      },
      "source": [
        "# Welcome to the first part of the ML image analysis and classification workshop!\n",
        "\n",
        "### In this notebook you will do some basic analysis of a dataset. The tasks consist of dataloading using pathlib and applying an image transform using opencv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlMKdFYoxr_a"
      },
      "source": [
        "## <ins>START COMMANDS</ins>\n",
        "\n",
        "#### In this first cell we run some commands that move Kaggle API keys to the right place and download and unzip the data :-) In the second cell we run the basic imports that you might need. Feel free to import more libraries if you need!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wADHBGvyDJ1H",
        "outputId": "284783fb-6ade-4c7c-9706-26444cf5c40e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We start by running this cell to make sure that all relevant files are present in the folder structure\n",
        "!git clone https://github.com/NordAxon/NBI-Handelsakademin-ML-Labs.git\n",
        "\n",
        "# We move the Kaggle API token to where Colab wants it\n",
        "!mkdir -p ~/.kaggle/ && mv NBI-Handelsakademin-ML-Labs/kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# We download the kaggle dataset\n",
        "!kaggle datasets download -d suddirutten/covid-xray-modified\n",
        "\n",
        "# And we unzip the dataset and put it in the image-lab folder :-)\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/covid-xray-modified.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/NBI-Handelsakademin-ML-Labs/image-lab\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NBI-Handelsakademin-ML-Labs'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 64 (delta 11), reused 59 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (64/64), done.\n",
            "Downloading covid-xray-modified.zip to /content\n",
            " 52% 9.00M/17.3M [00:01<00:01, 5.12MB/s]\n",
            "100% 17.3M/17.3M [00:01<00:00, 11.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tKi5qBPDJ1I"
      },
      "source": [
        "# Run this cell to import all neccesary packages\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import random\n",
        "from collections import defaultdict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty75L9T70Vba"
      },
      "source": [
        "## <ins>BACKGROUND</ins>\n",
        "We will analyse a dataset of X-Ray images that consists of 3 classes - Covid19, Viral Pneumonia and Normal. You can explore the dataset under __/content/NBI-Handelsakademin-ML-Labs/image-lab/Covid19-dataset/raw__ or https://www.kaggle.com/suddirutten/covid-xray-modified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM6A0SVoDJ1J"
      },
      "source": [
        "## <ins>EXERCISE 1 - Analysis</ins>\n",
        "\n",
        "### Your first task is to read in all images from the dataset and analyze them\n",
        "We want you to read the images into one list and thus be able to find the sizes of the tensors (=images)\n",
        "\n",
        "__You should be able to answer the following questions after this exercise__:\n",
        "\n",
        "- What shapes are the images?\n",
        "- How many images are there, per class, in the training and test set?\n",
        "- There are 3 channels in each image, is this necessary? (I.e. is the data unique over the channels?)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiHBXVcdDJ1J"
      },
      "source": [
        "# Point to dataset path\n",
        "path_to_images = Path(\"/content/NBI-Handelsakademin-ML-Labs/image-lab/Covid19-dataset/raw\")\n",
        "\n",
        "## Enter your solution below. Use as many cells as you wish :-)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va-LvEF1DJ1K"
      },
      "source": [
        "#### Optional hints for solving the task:\n",
        "- By using pathlib, we can glob our way through all images and find them immediately. Example: path_dir.rglob('*.xslx') finds all excel files (that end on .xslx) recursively in the path_dir\n",
        "- Using the pathlib parent and name property, we can easily find the class and set of an image\n",
        "- Saving the number of images found in a nested dict makes it easy to read (both code and output). Creating a nested dict is possible through dict_name = defaultdict(lambda: defaultdict(int)), or dict_name = {{}}. defaultdict is neat as we do not need to check for existing keys when handling the dict.\n",
        "- Using cv2 we can read images into a numpy array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o8jITOcDJ1L"
      },
      "source": [
        "## <ins>BACKGROUND</ins>\n",
        "Assume that you have done a basic pixel value distribution analysis on the images and hypothesize that a contrast/brightness adjustment could be useful. To apply a transform like this you will use the ready-to-go method __createCLAHE__ from opencv.\n",
        "\n",
        "## <ins>EXERCISE 2 - Pre-processing</ins>\n",
        "\n",
        "### Your second task is to apply some pre-processing techniques to your images\n",
        "\n",
        "You will apply one pre-processing technique to one channel of each image, and save them in a separate folder. This folder will follow the folder structure as for the raw data, but instead lie in the folder \"Covid19-dataset/processed\". Each image should be named the same as under the raw folder.\n",
        "\n",
        "__You should be able to answer the following questions after this exercise__:\n",
        "- Looking at one picture, how did the pixel value distribution change after applying a CLAHE function to the image?\n",
        "- What hyperparameters did you try? How did they affect the distribution and how the image looked?\n",
        "- Do you think this pre-processing technique could aid an ML model when training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZZI3w4fDJ1M"
      },
      "source": [
        "## Enter your solution below. Use as many cells as you wish :-)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}