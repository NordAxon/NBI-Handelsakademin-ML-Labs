{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd042641d1e4ddc0439bc830f06160e1b86a530aa5e4e7d97ad1497406e82138f19",
   "display_name": "Python 3.8.5 64-bit ('tensorflow': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "42641d1e4ddc0439bc830f06160e1b86a530aa5e4e7d97ad1497406e82138f19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Welcome to the first part of the ML image analysis and classification workshop!\n",
    "\n",
    "In this notebook you will do some basic analysis of the images in the dataset that we will analyse."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import all neccesary packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "source": [
    "## 1) Analysis\n",
    "\n",
    "### Your first task is to read in all images from the dataset and analyze them\n",
    "We want you to read the images into one list and thus be able to find the sizes of the tensors (=images)\n",
    "\n",
    "You should be able to answer the following questions after this exercise:\n",
    "\n",
    "- What shapes are the images?\n",
    "- How many images are there, per class, in the training and test set?\n",
    "- There are 3 channels in each image, is this necessary? (I.e. is the data unique over the channels?)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code from here on below\n",
    "# Use as many cells as you wish\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Optional hints for solving the first task:\n",
    "- By using pathlib, we can glob our way through all images and find them immediately. Example: path_dir.rglob('*.xslx') finds all excel files (that end on .xslx) recursively in the path_dir\n",
    "- Using the pathlib parent and name property, we can easily find the class and set of an image\n",
    "- Saving the number of images found in a nested dict makes it easy to read (both code and output). Creating a nested dict is possible through dict_name = defaultdict(lambda: defaultdict(int)), or dict_name = {{}}. defaultdict is neat as we do not need to check for existing keys when handling the dict.\n",
    "- Using cv2 we can read images into a numpy array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2) Pre-processing\n",
    "### Your second task is to apply some pre-processing techniques to your images\n",
    "Assume that you have done a basic pixel value distribution analysis on the images and hypothesize that a contrast/brightness adjustment could be useful. To apply a transform like this you will use ready-to-go methods from opencv.\n",
    "\n",
    "You will apply one pre-processing technique to one channel of each image, and save them in a separate folder. This folder will follow the folder structure as for the raw data, but instead lie in the folder \"Covid19-dataset/processed\"\n",
    "\n",
    "You should be able to answer the following questions after this exercise:\n",
    "- Looking at one picture, how did the pixel value distribution change after applying a CLAHE function to the image?\n",
    "- What hyperparameters did you try? How did they affect the distribution and how the image looked?\n",
    "- Do you think this pre-processing technique could aid an ML model when training?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code from here on below\n",
    "# Use as many cells as you wish\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Optional hints for solving the second task\n",
    "- Use matrix slicing to only get one channel of each image\n",
    "- Use OpenCVs method for CLAHE\n",
    "\n",
    "### BONUS POINTS if you plot some before and after images together with their respective pixel distributions\n",
    "### BONUS POINTS if you do a more in depth analysis of how the pixel value distributions change over more samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}